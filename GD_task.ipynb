{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ShlhjtsXiNydhg0COLUZfzZ5zCkLDNEd","timestamp":1672414404287}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Градиентный спуск. Практика"],"metadata":{"id":"2rIeJvNmzPJy"}},{"cell_type":"markdown","source":["## Импорт библиотек, установка константных значений"],"metadata":{"id":"krXvdp0bzfJK"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.datasets import make_regression"],"metadata":{"id":"X6AuQbUpziB8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["RANDOM_STATE = 42\n","TRAIN_SIZE = 0.75\n","\n","np.random.RandomState(RANDOM_STATE);"],"metadata":{"id":"47ZRimlw6TEp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Задание 1"],"metadata":{"id":"Taoqwoj1zS4U"}},{"cell_type":"markdown","source":["\n","Напишите функцию, вычисляющую значение весов в линейной регрессии по точной (аналитически найденной) формуле:\n","\n","$$w = (X^TX)^{-1}X^Ty$$\n","\n","Комментарий: для поиска решения в векторном виде сначала необходимо добавить единичный столбец к матрице $X$.  \n","Это сделано в коде."],"metadata":{"id":"lm6_Ln0GoliG"}},{"cell_type":"code","source":["def ols_solution(X, y):\n","    X = np.hstack((np.ones((X.shape[0], 1)), X))\n","    # your code here"],"metadata":{"id":"ZrVvpU9miOga"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Заполните функцию для предсказания модели по формуле\n","$$a(X)=Xw$$"],"metadata":{"id":"AMBKhU7Zhaev"}},{"cell_type":"code","source":["def prediction(X, w):\n","    X = np.hstack((np.ones((X.shape[0], 1)), X))\n","    # your code here"],"metadata":{"id":"CI63O1eUhmyx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Продублируем функцию для вычисления значения MSE из урока"],"metadata":{"id":"OaPciXsEmznh"}},{"cell_type":"code","source":["def compute_cost(X, y, theta):  \n","    m = len(y)\n","    cost = (1./m) * (np.linalg.norm(X @ theta - y) ** 2)\n","\n","    return cost"],"metadata":{"id":"PqzBobT-m28D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Задание 2"],"metadata":{"id":"l1EApEeW1OyU"}},{"cell_type":"markdown","source":["### Задание 2.1"],"metadata":{"id":"JXbV8Luk4-TE"}},{"cell_type":"markdown","source":["Примените метод градиентного спуска из библиотеки `sklearn` для решения задачи."],"metadata":{"id":"VFANmcnV5DWz"}},{"cell_type":"code","source":["# ваш код здесь"],"metadata":{"id":"VB9oE8Sg1WG9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Задание 2.2 (бонус для отважных)"],"metadata":{"id":"X_3A_UGWztbY"}},{"cell_type":"markdown","source":["Если чувствуете в себе силы, попробуйте написать SGD сами."],"metadata":{"id":"GMujXdy75Lb2"}},{"cell_type":"markdown","source":["Модифицируйте метод градиентного спуска из урока так, чтобы это теперь был метод стохастического градиентного спуска:\n","\n","* на каждой итерации выбирайте один случайный индекс `ind` при помощи библиотеки `numpy.random`\n","\n","* градиент на каждой итерации градиентного спуска считайте не как сумму градиентов по всем объектам, а только по одному объекту с индексом `ind`\n","\n","* на каждой итерации вычисляйте значение функции потерь и сохраняйте в список `loss`, который верните вместе с результатом работы функции"],"metadata":{"id":"_shCsTQ1pVcU"}},{"cell_type":"code","source":["def stochastic_gradient_descent(X, y, learning_rate, iterations):\n","    # your code here"],"metadata":{"id":"fTZWxz1zpb9R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Задание 3"],"metadata":{"id":"ss8jAfZVz6bz"}},{"cell_type":"markdown","source":["- Скопируйте метод градиентного спуска из семинара в этот ноутбук.\n","\n","- Обучите линейную регрессию тремя методами (по точной формуле, с помощью GD и с помощью SGD) на данных для задачи регрессии (см. код ниже). Для GD и самостоятельно написанного SGD используйте `learning_rate = 0.01, iterations = 10000`.\n","\n","- С помощью каждого метода сделайте предсказание (на всех данных), вычислите качество предсказания r2 (`from sklearn.metrics import r2_score`). Для получения предсказания можете использовать функцию `predict` из урока.\n"],"metadata":{"id":"WnRlUa9Npi9o"}},{"cell_type":"code","source":["# your code for GD here"],"metadata":{"id":"O_MDhoXs5tkd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Вопросы по заданию**\n","\n","1) все ли методы справились с нахождением минимума? \n","\n","2) сравните время работы методов (используйте библиотеку `time`): замеряйте время работы соответствующей написанной вами функции. Какой метод сработал быстрее всего?\n","\n","3) для методов GD и SGD нарисуйте графики (для каждого свой) зависимости ошибки (loss) от номера итерации. Какой метод сходится быстрее? Выведите на экран значение r2 для наилучшей из моделей.\n","\n","4) какой метод успешнее всего справился с задачей? (т.е. r2 наибольший)."],"metadata":{"id":"q5-LlK5X0Hdj"}},{"cell_type":"code","source":["X, y, _ = make_regression(n_samples=100000, # число объектов\n","                          n_features=10, # число признаков\n","                          n_informative=8, # число информативных признаков \n","                          noise=100, # уровень шума в данных\n","                          coef=True, # значение True исползуется при генерации данных\n","                          random_state=RANDOM_STATE) \n","\n","X = pd.DataFrame(data=X, columns=np.arange(0, X.shape[1]))\n","X[10] = X[6] + X[7] + np.random.random()*0.01"],"metadata":{"id":"LBu41KSpqbbI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# your code here:\n","# 1 - находим веса одним из методов\n","# 2 - применяем функцию prediction для получения предсказаний с найденными весами\n","# 3 - вычисляем значение метрики r2\n"],"metadata":{"id":"f1SE0-oUtVlO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Тестирование моделей на реальных данных\n","\n","В реальных задачах никто не пишет методы с нуля, если они уже реализованы в python. Самостоятельная реализация методов полезна для получения навыков программирования и более глубокого понимания алгоритмов.\n","\n","Давайте применим уже готовые методы из `sklearn` для решения задачи регрессии."],"metadata":{"id":"7Lne3c3I1swS"}},{"cell_type":"code","source":["from sklearn.datasets import fetch_california_housing\n","\n","data = fetch_california_housing(as_frame=True)\n","\n","X = data.data\n","y = data.target"],"metadata":{"id":"qUhkRgYm1usp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Разобъем данные на трейн и тест"],"metadata":{"id":"BlsxS_mb18A8"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, \n","                                                    train_size=TRAIN_SIZE, \n","                                                    random_state=RANDOM_STATE)"],"metadata":{"id":"tKKC-nWE13ek"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Для решения этой задачи попробуйте следующие модели:\n","\n","* LinearRegression из sklearn\n","* SGDRegressor из sklearn\n","\n","Обучите модели на тренировочных данных с параметрами по умолчанию и сделайте предсказание на тесте.  \n","Вычислите значение $R^2$."],"metadata":{"id":"1nxiq6Uq2K47"}},{"cell_type":"code","source":["# your code here"],"metadata":{"id":"PdoNyLJy165x"},"execution_count":null,"outputs":[]}]}